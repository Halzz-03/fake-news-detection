{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_UAAFaahIVf"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # To create and manipulate numpy arrays\n",
        "import pandas as pd  # To create and manage data using DataFrames\n",
        "import re  # Regular expressions for text preprocessing\n",
        "from nltk.corpus import stopwords  # List of common words (e.g., \"the\", \"is\") to be removed\n",
        "from nltk.stem.porter import PorterStemmer  # Stemming: Converting words to their root form (e.g., \"running\" -> \"run\")\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Converts text into numerical vectors for ML\n",
        "from sklearn.model_selection import train_test_split  # Splits dataset into training and testing sets\n",
        "from sklearn.linear_model import LogisticRegression  # Logistic Regression model for classification\n",
        "from sklearn.metrics import accuracy_score  # To evaluate model accuracy\n",
        "\n",
        "# Download stopwords dataset from NLTK\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Display the list of stopwords in English\n",
        "print(stopwords.words('english'))\n",
        "\n",
        "# Data Collection and Preprocessing\n",
        "\n",
        "# Load dataset into a pandas DataFrame\n",
        "news_dataset = pd.read_csv('/content/train.csv')\n",
        "\n",
        "# Check the shape of the dataset (number of rows and columns)\n",
        "print(news_dataset.shape)\n",
        "\n",
        "# Display the first 5 rows of the dataset\n",
        "print(news_dataset.head())\n",
        "\n",
        "# Display the first 20 lines of the dataset for reference\n",
        "!head -20 /content/train.csv\n",
        "\n",
        "# Check for missing values in each column\n",
        "print(news_dataset.isnull().sum())  # Some articles may have missing author names or titles\n",
        "\n",
        "# Replace null values with empty strings to avoid errors\n",
        "news_dataset = news_dataset.fillna('')\n",
        "\n",
        "# Combine 'author' and 'title' columns into a new 'content' column (text input for prediction)\n",
        "news_dataset['content'] = news_dataset['author'] + ' ' + news_dataset['title']\n",
        "\n",
        "# Display the newly created 'content' column\n",
        "print(news_dataset['content'])\n",
        "\n",
        "# Separating features (X) and labels (Y)\n",
        "X = news_dataset.drop(columns='label', axis=1)  # Features (text content)\n",
        "Y = news_dataset['label']  # Labels (0 for real news, 1 for fake news)\n",
        "\n",
        "# Display features and labels\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "# Function for text preprocessing using stemming\n",
        "def stemming(content):\n",
        "    port_stem = PorterStemmer()  # Initialize PorterStemmer\n",
        "\n",
        "    # Remove special characters and numbers, keeping only alphabets\n",
        "    stemmed_content = re.sub(r'[^\\w\\s]', '', content)\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    stemmed_content = stemmed_content.lower()\n",
        "\n",
        "    # Tokenize: Split text into words\n",
        "    stemmed_content = stemmed_content.split()\n",
        "\n",
        "    # Apply stemming and remove stopwords\n",
        "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if word not in stopwords.words('english')]\n",
        "\n",
        "    # Join words back into a string\n",
        "    return ' '.join(stemmed_content)\n",
        "\n",
        "# Apply stemming to the 'content' column\n",
        "news_dataset['content'] = news_dataset['content'].apply(stemming)\n",
        "\n",
        "# Display preprocessed content\n",
        "print(news_dataset['content'])\n",
        "\n",
        "# Convert text into numerical format\n",
        "X = news_dataset['content'].values  # Features (text data)\n",
        "Y = news_dataset['label'].values  # Labels (0 = real, 1 = fake)\n",
        "\n",
        "print(X)\n",
        "print(Y)\n",
        "\n",
        "# Convert text data into numerical vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# TF-IDF (Term Frequency-Inverse Document Frequency)\n",
        "# - TF: Counts how often a word appears in a document\n",
        "# - IDF: Reduces importance of words that appear too frequently across all documents\n",
        "vectorizer.fit(X)\n",
        "X = vectorizer.transform(X)\n",
        "print(X)  # Display numerical representation of text\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
        "\n",
        "# - test_size=0.2: 20% of the data is used for testing\n",
        "# - stratify=Y: Ensures class distribution remains the same in train and test sets\n",
        "# - random_state=2: Ensures reproducibility of the split\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model using training data\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Predict labels for training data\n",
        "X_train_prediction = model.predict(X_train)\n",
        "\n",
        "# Calculate and print accuracy on training data\n",
        "training_data_accuracy = accuracy_score(X_train_prediction, Y_train)\n",
        "print('Accuracy score of training data:', training_data_accuracy)\n",
        "\n",
        "# Predict labels for test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy on test data\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)\n",
        "print('Accuracy score of test data:', test_data_accuracy)\n",
        "\n",
        "# Making a predictive system (Fake News Detection)\n",
        "\n",
        "# Select a new test example (first row from test set)\n",
        "X_new = X_test[0]\n",
        "\n",
        "# Predict whether the news is real or fake\n",
        "prediction = model.predict(X_new)\n",
        "print(prediction)\n",
        "\n",
        "# Print result based on prediction\n",
        "if prediction[0] == 0:\n",
        "    print('The news is real')\n",
        "else:\n",
        "    print('The news is fake')\n"
      ]
    }
  ]
}